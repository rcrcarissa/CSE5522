{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CSE5522-Assignment1-1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNphB/9lJZLGq6WktjlAsDQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rcrcarissa/CSE5522/blob/main/CSE5522_Assignment1_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2NqbHFJ3n6oF"
      },
      "source": [
        "# **Problem 1: Mars Rover Problem**\n",
        "\n",
        "1.0: Set up the environment."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QVPXLMHdnjD0"
      },
      "source": [
        "import networkx as nx"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4RqsDWmfn5W6"
      },
      "source": [
        "1.1: Initialize 1) the graph, including structure, gains of path cost (edge weights), and heuristic function (node weights) and 2) initial state."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "svV8pWGyooKJ"
      },
      "source": [
        "G = nx.Graph()\n",
        "G.add_nodes_from([(\"Alpha\",{'weight':15}), (\"Beta\",{'weight':0}), (\"Gamma\",{'weight':12}), (\"Delta\",{'weight':15}), (\"Epsilon\",{'weight':20}), (\"Zeta\",{'weight':20}), (\"Eta\",{'weight':25})])\n",
        "G.add_edges_from([(\"Alpha\", \"Gamma\", {'weight':10}), (\"Alpha\", \"Beta\", {'weight':15}), (\"Gamma\", \"Delta\", {'weight':15}), (\"Gamma\", \"Beta\", {'weight':12}), (\"Beta\", \"Zeta\", {'weight':20}), (\"Delta\", \"Epsilon\", {'weight':10}), (\"Zeta\", \"Epsilon\", {'weight':8}), (\"Epsilon\", \"Eta\", {'weight':10}), (\"Zeta\", \"Eta\", {'weight':7})])\n",
        "G = G.to_undirected()\n",
        "\n",
        "initial_state = \"Alpha F F\"  # initial node, sample from Delta, sample from Eta\n",
        "goal = [\"Beta\", \"Delta\", \"Eta\"] # first: goal station; others: all other stations to be visited"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JNAJebm3slAb"
      },
      "source": [
        "1.2: Uniform Cost Search. Returns the search tree, all nodes that have been expanded, and queue size at the end."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EUQorknD-Ny5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "e73a5de1-912f-45ad-b99d-c4a1080056b9"
      },
      "source": [
        "def UniformCostSearch(G, initial_state, goal):\n",
        "  # priority queue, with separated states, steps, and costs\n",
        "  queue_nodes = []\n",
        "  queue_samples = []\n",
        "  queue_steps = []\n",
        "  queue_weights = []\n",
        "  # record of steps and costs\n",
        "  trace = nx.Graph()  # the search tree\n",
        "  previous_state = initial_state + \" 0\" * 2  # first node in the search tree\n",
        "  trace.add_node(previous_state)\n",
        "  expanded_nodes = [previous_state]\n",
        "\n",
        "  while True:\n",
        "    # add new successors to the queue\n",
        "    current_state = previous_state.split(\" \")\n",
        "    current_node = current_state[0]\n",
        "    successors = list(G[current_node])\n",
        "    queue_nodes += successors\n",
        "    samples = current_state[1:-2]\n",
        "    steps = int(current_state[-2]) + 1\n",
        "    path_cost = int(current_state[-1])\n",
        "    queue_steps += [steps] * len(successors)\n",
        "    for node in successors:\n",
        "      weight = G.edges[current_node, node]['weight'] + path_cost\n",
        "      queue_weights.append(weight)\n",
        "      node_samples = samples\n",
        "      if node in goal[1:]:\n",
        "        idx = goal.index(node) - 1\n",
        "        node_samples[idx] = \"T\"\n",
        "      sample_str = \"\"\n",
        "      for sample in node_samples:\n",
        "        sample_str += (sample + \" \")\n",
        "      queue_samples.append(sample_str)\n",
        "      current_state = node + \" \" + sample_str + str(steps) + \" \" + str(weight)\n",
        "      trace.add_node(current_state)\n",
        "      trace.add_edge(previous_state, current_state)\n",
        "    # find the action with minimum cost\n",
        "    min_cost_idx = queue_weights.index(min(queue_weights))\n",
        "        \n",
        "    # goal test\n",
        "    if queue_nodes[min_cost_idx] == goal[0] and \"F\" not in queue_samples[min_cost_idx]:\n",
        "      return trace, expanded_nodes, len(queue_nodes)\n",
        "    else:\n",
        "      # update state\n",
        "      previous_state = queue_nodes[min_cost_idx] + \" \" + queue_samples[min_cost_idx] + str(queue_steps[min_cost_idx]) + \" \" + str(queue_weights[min_cost_idx])\n",
        "      expanded_nodes.append(previous_state)\n",
        "      del queue_nodes[min_cost_idx], queue_samples[min_cost_idx], queue_steps[min_cost_idx], queue_weights[min_cost_idx]  # update queue\n",
        "\n",
        "trace, expanded_nodes, queue_size = UniformCostSearch(G, initial_state, goal)  # search tree, list of all nodes that have been expanded, and queue size at the end\n",
        "print(\"number of nodes in search tree: \" + str(trace.number_of_nodes()))\n",
        "print(\"times of expanding a node: \" + str(len(expanded_nodes)))\n",
        "print(\"queue size: \" + str(queue_size))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "number of nodes in search tree: 347\n",
            "times of expanding a node: 258\n",
            "queue size: 419\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d4MCnQG9-Os6"
      },
      "source": [
        "1.3: Greedy Best First Search. Returns the search tree, all nodes that have been expanded, and queue size at the end."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0je6sjrO-TIu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 409
        },
        "outputId": "72092552-a5e7-4e87-a65f-94b712019d94"
      },
      "source": [
        "def GreedyBestFirstSearch(G, initial_state, goal):\n",
        "  # priority queue, with separated states, steps, and costs\n",
        "  queue_nodes = []\n",
        "  queue_samples = []\n",
        "  queue_steps = []\n",
        "  queue_weights = []\n",
        "  queue_f = []\n",
        "  # record of steps and costs\n",
        "  trace = nx.Graph()  # the search tree\n",
        "  previous_state = initial_state + \" 0\" * 3  # first node in the search tree\n",
        "  trace.add_node(previous_state)\n",
        "  expanded_nodes = [previous_state]\n",
        "\n",
        "  while True:\n",
        "    # add new successors to the queue\n",
        "    current_state = previous_state.split(\" \")\n",
        "    current_node = current_state[0]\n",
        "    successors = list(G[current_node])\n",
        "    queue_nodes += successors\n",
        "    samples = current_state[1:-3]\n",
        "    steps = int(current_state[-3]) + 1\n",
        "    path_cost = int(current_state[-2])\n",
        "    queue_steps += [steps] * len(successors)\n",
        "    for node in successors:\n",
        "      weight = G.edges[current_node, node]['weight'] + path_cost\n",
        "      queue_weights.append(weight)\n",
        "      f = G.nodes[current_node]['weight']\n",
        "      queue_f.append(f)\n",
        "      node_samples = samples\n",
        "      if node in goal[1:]:\n",
        "        idx = goal.index(node) - 1\n",
        "        node_samples[idx] = \"T\"\n",
        "      sample_str = \"\"\n",
        "      for sample in node_samples:\n",
        "        sample_str += (sample + \" \")\n",
        "      queue_samples.append(sample_str)\n",
        "      current_state = node + \" \" + sample_str + str(steps) + \" \" + str(weight) + str(f)\n",
        "      trace.add_node(current_state)\n",
        "      trace.add_edge(previous_state, current_state)\n",
        "    # find the action with minimum cost\n",
        "    min_cost_idx = queue_f.index(min(queue_f))\n",
        "        \n",
        "    # goal test\n",
        "    if queue_nodes[min_cost_idx] == goal[0] and \"F\" not in queue_samples[min_cost_idx]:\n",
        "      return trace, expanded_nodes, len(queue_nodes)\n",
        "    else:# update state\n",
        "      previous_state = queue_nodes[min_cost_idx] + \" \" + queue_samples[min_cost_idx] + str(queue_steps[min_cost_idx]) + \" \" + str(queue_weights[min_cost_idx]) + \" \" + str(queue_f[min_cost_idx])\n",
        "      expanded_nodes.append(previous_state)\n",
        "      del queue_nodes[min_cost_idx], queue_samples[min_cost_idx], queue_steps[min_cost_idx], queue_weights[min_cost_idx], queue_f[min_cost_idx]  # update queue\n",
        "\n",
        "trace, expanded_nodes, queue_size = GreedyBestFirstSearch(G, initial_state, goal)  # search tree, list of all nodes that have been expanded, and queue size at the end\n",
        "print(\"number of nodes in search tree: \" + str(trace.number_of_nodes()))\n",
        "print(\"times of expanding a node: \" + str(len(expanded_nodes)))\n",
        "print(\"queue size: \" + str(queue_size))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-6d4a1c47121d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     49\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mqueue_nodes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmin_cost_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqueue_samples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmin_cost_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqueue_steps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmin_cost_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqueue_weights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmin_cost_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqueue_f\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmin_cost_idx\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# update queue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m \u001b[0mtrace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpanded_nodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqueue_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGreedyBestFirstSearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgoal\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# search tree, list of all nodes that have been expanded, and queue size at the end\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"number of nodes in search tree: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumber_of_nodes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"times of expanding a node: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpanded_nodes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-17-6d4a1c47121d>\u001b[0m in \u001b[0;36mGreedyBestFirstSearch\u001b[0;34m(G, initial_state, goal)\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mqueue_steps\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msuccessors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mnode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msuccessors\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m       \u001b[0mweight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medges\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcurrent_node\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'weight'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mpath_cost\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m       \u001b[0mqueue_weights\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m       \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcurrent_node\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'weight'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/networkx/classes/graph.py\u001b[0m in \u001b[0;36medges\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1295\u001b[0m         \u001b[0mEdgeDataView\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1296\u001b[0m         \"\"\"\n\u001b[0;32m-> 1297\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mEdgeView\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1298\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1299\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_edge_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/networkx/classes/reportviews.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, G)\u001b[0m\n\u001b[1;32m    990\u001b[0m     \u001b[0mdataview\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOutEdgeDataView\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    991\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 992\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mG\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    993\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mG\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    994\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_adjdict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_succ\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"succ\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_adj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-eEQWrdw-Tjf"
      },
      "source": [
        "1.4: A* Search. Returns the search tree, all nodes that have been expanded, and queue size at the end."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "72vlJdJ8-XMx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "903ec1e0-cac3-4538-feb2-94f4c490b54b"
      },
      "source": [
        "def AStarSearch(G, initial_state, goal):\n",
        "  # priority queue, with separated states, steps, and costs\n",
        "  queue_nodes = []\n",
        "  queue_samples = []\n",
        "  queue_steps = []\n",
        "  queue_weights = []\n",
        "  queue_f = []\n",
        "  # record of steps and costs\n",
        "  trace = nx.Graph()  # the search tree\n",
        "  previous_state = initial_state + \" 0\" * 3  # first node in the search tree\n",
        "  trace.add_node(previous_state)\n",
        "  expanded_nodes = [previous_state]\n",
        "\n",
        "  while True:\n",
        "    # add new successors to the queue\n",
        "    current_state = previous_state.split(\" \")\n",
        "    current_node = current_state[0]\n",
        "    successors = list(G[current_node])\n",
        "    queue_nodes += successors\n",
        "    samples = current_state[1:-3]\n",
        "    steps = int(current_state[-3]) + 1\n",
        "    path_cost = int(current_state[-2])\n",
        "    queue_steps += [steps] * len(successors)\n",
        "    for node in successors:\n",
        "      weight = G.edges[current_node, node]['weight'] + path_cost\n",
        "      queue_weights.append(weight)\n",
        "      f = weight + G.nodes[current_node]['weight']\n",
        "      queue_f.append(f)\n",
        "      node_samples = samples\n",
        "      if node in goal[1:]:\n",
        "        idx = goal.index(node) - 1\n",
        "        node_samples[idx] = \"T\"\n",
        "      sample_str = \"\"\n",
        "      for sample in node_samples:\n",
        "        sample_str += (sample + \" \")\n",
        "      queue_samples.append(sample_str)\n",
        "      current_state = node + \" \" + sample_str + str(steps) + \" \" + str(weight) + str(f)\n",
        "      trace.add_node(current_state)\n",
        "      trace.add_edge(previous_state, current_state)\n",
        "    # find the action with minimum cost\n",
        "    min_cost_idx = queue_f.index(min(queue_f))\n",
        "        \n",
        "    # goal test\n",
        "    if queue_nodes[min_cost_idx] == goal[0] and \"F\" not in queue_samples[min_cost_idx]:\n",
        "      return trace, expanded_nodes, len(queue_nodes)\n",
        "    else:# update state\n",
        "      previous_state = queue_nodes[min_cost_idx] + \" \" + queue_samples[min_cost_idx] + str(queue_steps[min_cost_idx]) + \" \" + str(queue_weights[min_cost_idx]) + \" \" + str(queue_f[min_cost_idx])\n",
        "      expanded_nodes.append(previous_state)\n",
        "      del queue_nodes[min_cost_idx], queue_samples[min_cost_idx], queue_steps[min_cost_idx], queue_weights[min_cost_idx], queue_f[min_cost_idx]  # update queue\n",
        "\n",
        "trace, expanded_nodes, queue_size = AStarSearch(G, initial_state, goal)  # search tree, list of all nodes that have been expanded, and queue size at the end\n",
        "print(\"number of nodes in search tree: \" + str(trace.number_of_nodes()))\n",
        "print(\"times of expanding a node: \" + str(len(expanded_nodes)))\n",
        "print(\"queue size: \" + str(queue_size))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "number of nodes in search tree: 861\n",
            "times of expanding a node: 420\n",
            "queue size: 677\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C9hEu6sKpkvw"
      },
      "source": [
        "1.5: Touring problem with the same starting point and destination. Uncomment one of the algorithm functions to excute it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fUqU_5DGqBEk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "c3f4d4c9-d482-4c38-a326-107cfe8b7ce1"
      },
      "source": [
        "initial_state = \"Alpha F F F F F F\"  # initial node, visit other cities or not\n",
        "goal = [\"Alpha\", \"Beta\", \"Gamma\", \"Zeta\", \"Delta\", \"Epsilon\", \"Eta\"] # first: goal station; others: all other stations to be visited\n",
        "\n",
        "######################## uncomment one of the algorithm functions below to excute it ########################\n",
        "# trace, expanded_nodes, queue_size = UniformCostSearch(G, initial_state, goal)\n",
        "# trace, expanded_nodes, queue_size = GreedyBestFirstSearch(G, initial_state, goal)\n",
        "trace, expanded_nodes, queue_size = AStarSearch(G, initial_state, goal)\n",
        "######################## uncomment one of the algorithm functions above to excute it ########################\n",
        "\n",
        "print(\"number of nodes in search tree: \" + str(trace.number_of_nodes()))\n",
        "print(\"times of expanding a node: \" + str(len(expanded_nodes)))\n",
        "print(\"queue size: \" + str(queue_size))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "number of nodes in search tree: 898\n",
            "times of expanding a node: 422\n",
            "queue size: 681\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3TKkGuHSRz4V"
      },
      "source": [
        "1.6: Touring problem with different starting point and destination. Uncomment one of the algorithm functions to excute it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9VSUwNGwUhYA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "f466e4c2-c1a6-4837-f519-f8f0ac875ae4"
      },
      "source": [
        "initial_state = \"Alpha F F F F F\"  # initial node, visit other cities or not\n",
        "goal = [\"Eta\", \"Beta\", \"Gamma\", \"Zeta\", \"Delta\", \"Epsilon\"] # first: goal station; others: all other stations to be visited\n",
        "\n",
        "######################## uncomment one of the algorithm functions below to excute it ########################\n",
        "# trace, expanded_nodes, queue_size = UniformCostSearch(G, initial_state, goal)\n",
        "# trace, expanded_nodes, queue_size = GreedyBestFirstSearch(G, initial_state, goal)\n",
        "trace, expanded_nodes, queue_size = AStarSearch(G, initial_state, goal)\n",
        "######################## uncomment one of the algorithm functions above to excute it ########################\n",
        "\n",
        "print(\"number of nodes in search tree: \" + str(trace.number_of_nodes()))\n",
        "print(\"times of expanding a node: \" + str(len(expanded_nodes)))\n",
        "print(\"queue size: \" + str(queue_size))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "number of nodes in search tree: 173\n",
            "times of expanding a node: 52\n",
            "queue size: 85\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SMBwySsF4QAy"
      },
      "source": [
        "1.7: Simplified Memory-Bounded A* Search."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ByQdW2Xe4h_w",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "c897a01f-22bc-42a0-b6ce-5cb394c4b990"
      },
      "source": [
        "initial_state = \"Alpha F F\"  # initial node, sample from Delta, sample from Eta\n",
        "goal = [\"Beta\", \"Delta\", \"Eta\"] # first: goal station; others: all other stations to be visited\n",
        "\n",
        "def SMAStarSearch(G, initial_state, goal):\n",
        "  # priority queue, with separated states, steps, and costs\n",
        "  queue_nodes = []\n",
        "  queue_samples = []\n",
        "  queue_steps = []\n",
        "  queue_weights = []\n",
        "  queue_f = []\n",
        "  # record of steps and costs\n",
        "  trace = nx.Graph()  # the search tree\n",
        "  previous_state = initial_state + \" 0\" * 3  # first node in the search tree\n",
        "  trace.add_node(previous_state)\n",
        "  expanded_nodes = [previous_state]\n",
        "  search_tree_num_nodes = 20\n",
        "\n",
        "  while True:\n",
        "    # add new successors to the queue\n",
        "    current_state = previous_state.split(\" \")\n",
        "    current_node = current_state[0]\n",
        "    successors = list(G[current_node])\n",
        "    queue_nodes += successors\n",
        "    samples = current_state[1:-3]\n",
        "    steps = int(current_state[-3]) + 1\n",
        "    path_cost = int(current_state[-2])\n",
        "    queue_steps += [steps] * len(successors)\n",
        "    for node in successors:\n",
        "      weight = G.edges[current_node, node]['weight'] + path_cost\n",
        "      queue_weights.append(weight)\n",
        "      f = weight + G.nodes[current_node]['weight']\n",
        "      queue_f.append(f)\n",
        "      node_samples = samples\n",
        "      if node in goal[1:]:\n",
        "        idx = goal.index(node) - 1\n",
        "        node_samples[idx] = \"T\"\n",
        "      sample_str = \"\"\n",
        "      for sample in node_samples:\n",
        "        sample_str += (sample + \" \")\n",
        "      queue_samples.append(sample_str)\n",
        "      current_state = node + \" \" + sample_str + str(steps) + \" \" + str(weight) + str(f)\n",
        "      trace.add_node(current_state)\n",
        "      trace.add_edge(previous_state, current_state)\n",
        "    # check if dropping old nodes is needed\n",
        "    while trace.number_of_nodes() > search_tree_num_nodes:\n",
        "      f_values = []\n",
        "      node_list = list(trace.nodes())\n",
        "      for each_node in node_list:\n",
        "        f_values.append(int(each_node.split(\" \")[-1]))\n",
        "      max_f = max(f_values)\n",
        "      tree_idx = f_values.index(max_f)\n",
        "      node_to_remove = node_list[tree_idx]\n",
        "      trace.remove_node(node_to_remove)\n",
        "      # remove the node from queue if needed\n",
        "      if max_f in queue_f:\n",
        "        queue_idx = queue_f.index(max_f)\n",
        "        del queue_nodes[queue_idx], queue_samples[queue_idx], queue_steps[queue_idx], queue_weights[queue_idx], queue_f[queue_idx]\n",
        "    # find the action with minimum cost\n",
        "    min_cost_idx = queue_f.index(min(queue_f))\n",
        "        \n",
        "    # goal test\n",
        "    if queue_nodes[min_cost_idx] == goal[0] and \"F\" not in queue_samples[min_cost_idx]:\n",
        "      return trace, expanded_nodes, len(queue_nodes)\n",
        "    else:# update state\n",
        "      previous_state = queue_nodes[min_cost_idx] + \" \" + queue_samples[min_cost_idx] + str(queue_steps[min_cost_idx]) + \" \" + str(queue_weights[min_cost_idx]) + \" \" + str(queue_f[min_cost_idx])\n",
        "      expanded_nodes.append(previous_state)\n",
        "      del queue_nodes[min_cost_idx], queue_samples[min_cost_idx], queue_steps[min_cost_idx], queue_weights[min_cost_idx], queue_f[min_cost_idx]  # update queue\n",
        "\n",
        "trace, expanded_nodes, queue_size = SMAStarSearch(G, initial_state, goal)  # search tree, list of all nodes that have been expanded, and queue size at the end\n",
        "print(\"number of nodes in search tree: \" + str(trace.number_of_nodes()))\n",
        "print(\"times of expanding a node: \" + str(len(expanded_nodes)))\n",
        "print(\"queue size: \" + str(queue_size))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "number of nodes in search tree: 20\n",
            "times of expanding a node: 219\n",
            "queue size: 210\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}